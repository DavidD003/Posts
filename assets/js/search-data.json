{
  
    
        "post0": {
            "title": "Deploying A Schedule Building Algorithm",
            "content": "Context . Goal . Deploy an algorithm for schedulers to use that is: . -easy to use and learn . -transparent . -quick . -flexible . Motivation . In a 24/7 manufacturing environment, the weekend shifts are covered mostly by overtime, which is scheduled according to employee availability, subject to constraints outlined in the labour collective agreement. Due to changing production needs as well as staff availability, the schedule must be re-drafted many times, often on short notice and under tight time constraints. Drafting it is tedious, error-prone, and time consuming. It could be automated. . Challenges . -Data being manually entered in a variety of formats or not available in machine readable form. (e.g. total hours, employee type, employee availability, individualized job restrictions, outlier reasons for non-eligibility such as consecutive days worked) This is probably the main challenge!! . -Algorithm ambiguity. The collective agreement defines the constraints that each assignment decision is subject to, but doesn&#39;t strictly specify all aspects, allowing for arbitrary choice on schedulers part . -Many esoteric rules and edge cases around assignments being valid or not, which are also subject to change at time of contract renegotiation. . -Usability. The deployment must be available to all schedulers, and have a very low barrier to entry w.r.t. training and usability. . A Bit Of Lore . The notion of automating the process solution has been bouncing around my head for over a year. I always felt the main challenge was the situation posed by the data... the bad formatting relegated to excel sheets, necessarily made that way from human input and usage modality not being the same as what is best for machine readability. I am very confident I could make something that worked in VBA, but the nature of that language makes it such a pain to develop with, particularly with bad formatting. I knew python was a better solution, but didn&#39;t have the bridge between the two to make something that worked. Finally when following the FastAI course I came across the HFS+Gradio wombo combo for sharing python scripts publicly via a great UI. This discovery got me to finally choose to commit to that solution path . Solution . Codebase . Using Gradio hosted via HFS for making a python algorithm available with easy integration of inputs and outputs. At first blush I thought that Pandas DataFrames would be the best input mode for tabular data, but ruled that out when HFS didn&#39;t allow for bulk copying and pasting. Maybe that was for the best because this pushed me to figure out how to work with the generic File input/output mode. It might be a little more painful to program (have to define methods to identify the right tables within the excel file), but a lot nice on the end user experience (drag and drop relevant files and go!). I was concerned about the extra steps of processing the excel file, but as with everything Python there is a library for that! I started off with some basic tests to ensure that what I wanted/needed to do was possible. . File Manipulation . Here is my proof of concept for File manipulation. If copied into an empty Gradio space on HFS, it takes in an excel file, and adds a new table to the spreadsheet. This was all i needed to know that this could be done... . import gradio as gr import openpyxl as pyxl #openPyXl allows for excel file manipulation in python def myFunction(fl,txt): myWb=pyxl.load_workbook(fl.name) #Load excel file tab = pyxl.worksheet.table.Table(displayName=&quot;Table3&quot;, ref=&quot;E1:F5&quot;) #Define new table style = pyxl.worksheet.table.TableStyleInfo(name=&quot;TableStyleMedium9&quot;,showRowStripes=True, showColumnStripes=True) tab.tableStyleInfo = style #Assign style to table ws=myWb.active ws.add_table(tab) #Add defined table to sheet within the loaded workbook otpt_fl_name=&#39;try.xlsx&#39; myWb.save(otpt_fl_name) #Save file return otpt_fl_name #Define output for HFS interface demo = gr.Interface( myFunction, #Func to take in file and text [ gr.File( ), gr.Textbox( label=&quot;Initial text&quot;, lines=3, value=&quot;The quick brown fox jumped over the lazy dogs.&quot;, ), ], gr.File(), description=&quot;Enter refusal files&quot;, ) demo.launch() . Retrieving Disparate Tables . As mentioned previously, one challenge would be to pull data from tables scattered in an unpredictable way throughout the sheet. Here I had to remember that sometimes the easiest way to rob a bank is through the front door, not trying to break through the wall... I simply changed the existing excel template files (filled in by end user) so that the data tables were actually defined as &#39;Tables&#39; by excel... this made them reference-able by the openPyXl tools. Some further data type transformations were required. Example with a blank book containing a trivial data table called &#39;tstTbl&#39; in Excel: . import openpyxl as pyxl import pandas as pd import numpy as np myWb=pyxl.load_workbook(&#39;../images/Other_Files/TblTestBook.xlsx&#39;) #Didn&#39;t think the .. parent directory would work but it does! ws=myWb[&#39;Sheet1&#39;] tab=ws.tables[&#39;tstTbl&#39;] #Pull out table ref=tab.ref #Pull cell reference to string for display tab=[[x.value for x in sublist] for sublist in ws[tab.ref]] #Convert to list of lists (each sublist as row of excel table) tab=pd.DataFrame(tab) #Convert nested lists to Dataframe print(&#39;Table cells reference is &quot;&#39;+str(ref)+&#39;&quot;:&#39;) print(tab) . Table cells reference is &#34;A1:C4&#34;: 0 1 2 0 myHead1 myHead2 myHead3 1 1 a . 2 2 b , 3 3 c ] . And pulling info from multiple tables in a sheet . for t in ws.tables: tab=ws.tables[t] ref=tab.ref tab=[[x.value for x in sublist] for sublist in ws[tab.ref]] tab=pd.DataFrame(tab) print(&#39;Table cells reference is &quot;&#39;+str(ref)+&#39;&quot;:&#39;) print(tab) print(&#39;&#39;) . Table cells reference is &#34;A1:C4&#34;: 0 1 2 0 myHead1 myHead2 myHead3 1 1 a . 2 2 b , 3 3 c ] Table cells reference is &#34;G13:H17&#34;: 0 1 0 Names Hours 1 Alice 4 2 Bob 20 3 Clark 8 4 Dave 15 Table cells reference is &#34;G7:H11&#34;: 0 1 0 Names Hours 1 Arnold 4 2 Bill 60 3 Charles 53 4 Dick 10 Table cells reference is &#34;C18:D22&#34;: 0 1 0 Names Hours 1 Arthur 24 2 Blaire 70 3 Chuck 22 4 Darryl 12 . At this point I can say I am constantly resisting the urge to just run away with the coding! Trying to enforce a best practice of starting off with creating not just an abstract understanding of the problem, but a particular and specified framework in which I am operating, that is, figuring out the specific nature of the inputs I will have before I go nuts building my tower of babel! Next is to mock up a way to retrieve data when a worksheet has a single &#39;table&#39; not defined in Excel. That is, manually entered data in a tabular format that due to legacy sheet formatting is not able to be defined as a native Excel Table, precluding the use of table indexing seen in the previous example... My approach assumes a known top left cell, and knowing in my framework that only certain columns will be required here. . ws=myWb[&#39;Arb_Tbl&#39;] df = pd.DataFrame(ws.values) df . 0 1 2 3 4 5 6 7 8 . 0 None | None | None | None | None | None | None | None | None | . 1 None | None | None | None | None | None | None | None | None | . 2 Name | id | Attr1 | Attr2 | Attr3 | Attr4 | Attr5 | Attr6 | Attr7 | . 3 Bob Back | 0 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 4 Jeff Jahl | 1 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 5 Hodge Hoss | 2 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 6 Kev Kroll | 3 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 7 Tim Tin | 4 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . Above we can see the loose table in the wild... ws.values pulls the whole sheet, which would be good, except it grabs formulas. Unfortunately, per the docs, openPyXl will never evaluate formulas! Time to work smart, not hard. I choose to simply use the &#39;mouse wriggle&#39; technique shared at this webpage ( https://trumpexcel.com/convert-formulas-to-values-excel/ ) to manually convert formulas to values before passing my workbook into my functions. Though it is sad that the user experience won&#39;t be as smooth as dragging and dropping files. . myWb=pyxl.load_workbook(&#39;../images/Other_Files/TblTestBook.xlsx&#39;) #1st find bottom row with data for i in range(3,200): #Loop up to arbitrary number, prefer to have defined end for infinte loop stopgap ref=&quot;C&quot;+str(i) if ws[ref].internal_value==None: #Condition met when end of data found. btmRow=i-1 break tab=[[x.internal_value for x in sublist] for sublist in ws[&#39;A3:I&#39;+str(btmRow)]] df_IdNameHours=pd.DataFrame(tab) #Assuming column I is end of useful data df_IdNameHours . 0 1 2 3 4 5 6 7 8 . 0 Name | id | Attr1 | Attr2 | Attr3 | Attr4 | Attr5 | Attr6 | Attr7 | . 1 Bob Back | 0 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 2 Jeff Jahl | 1 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 3 Hodge Hoss | 2 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 4 Kev Kroll | 3 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | . 5 Tim Tin | 4 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | =RAND()*5 | .",
            "url": "https://davidd003.github.io/Posts/jupyter/2022/08/11/Deploying-A-Schedule-Building-Algorithm.html",
            "relUrl": "/jupyter/2022/08/11/Deploying-A-Schedule-Building-Algorithm.html",
            "date": " • Aug 11, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Building A Digit Classifier",
            "content": "from sklearn.datasets import load_digits mnist=load_digits() . mnist.keys() . dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;feature_names&#39;, &#39;target_names&#39;, &#39;images&#39;, &#39;DESCR&#39;]) . mnist[&#39;target&#39;] #Observing y value for data sequence . array([0, 1, 2, ..., 8, 9, 8]) . [list(mnist[&#39;target&#39;]).count(i) for i in range(10)] #Count of each digit in dataset . [178, 182, 177, 183, 181, 182, 181, 179, 174, 180] . len(mnist[&#39;target&#39;]) #Size of dataset . 1797 . mnist[&#39;images&#39;][-1]/16 . array([[0. , 0. , 0.625 , 0.875 , 0.5 , 0.0625, 0. , 0. ], [0. , 0.125 , 1. , 0.875 , 0.375 , 0.0625, 0. , 0. ], [0. , 0. , 0.9375, 0.9375, 0.5 , 0.9375, 0. , 0. ], [0. , 0. , 0.3125, 1. , 1. , 0.625 , 0. , 0. ], [0. , 0. , 0.75 , 0.9375, 0.9375, 0.75 , 0. , 0. ], [0. , 0.25 , 1. , 0.375 , 0.25 , 1. , 0.375 , 0. ], [0. , 0.5 , 1. , 0.625 , 0.5 , 1. , 0.5 , 0. ], [0. , 0.0625, 0.5 , 0.75 , 0.875 , 0.75 , 0.0625, 0. ]]) . show_image(mnist[&#39;images&#39;][-1]/16) #Visualizing example digit . &lt;AxesSubplot:&gt; . stacked=[] for i in range(10): #This loop because stacked=[[]]*10 makes 1 list in list, with 10 copies of pointers... need separate objects stacked.append([]) for i in range(len(mnist[&#39;target&#39;])): #Assign all images to the right collection in the &#39;stacked&#39; list, indexed by target stacked[mnist[&#39;target&#39;][i]].append(mnist[&#39;images&#39;][i]) . lens=[len(stacked[i]) for i in range(10)] lens, min(lens) #Confirm counts of samples . ([178, 182, 177, 183, 181, 182, 181, 179, 174, 180], 174) . stacked=tensor([x[:174] for x in stacked]) . /opt/conda/lib/python3.7/site-packages/fastai/torch_core.py:151: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1634272168290/work/torch/csrc/utils/tensor_new.cpp:201.) else torch.tensor(x, **kwargs) if isinstance(x, (tuple,list)) . test=[dig[-20:] for dig in stacked] train=[dig[:-20] for dig in stacked] . [len(test[i]) for i in range(10)],[len(train[i]) for i in range(10)] #Confirm counts of samples #Confirm counts of samples . ([20, 20, 20, 20, 20, 20, 20, 20, 20, 20], [154, 154, 154, 154, 154, 154, 154, 154, 154, 154]) . show_image(stacked[3][0]) #Check sample . &lt;AxesSubplot:&gt; . type(stacked),type(stacked[0]),type([stacked[0][0]]) #Check types . (torch.Tensor, torch.Tensor, list) . type(train),type(train[0]),type(train[0][0]),[type(test),type(test[0]),type(test[0][0])] . (list, torch.Tensor, torch.Tensor, [list, torch.Tensor, torch.Tensor]) . train=torch.stack(train) #Converts PyList of tensors to tensor of tesnors (join in new dimensions, retain target indexing) test=torch.stack(test) . train.shape,test.shape . (torch.Size([10, 154, 8, 8]), torch.Size([10, 20, 8, 8])) . stacked[0].ndim,stacked[0].shape #Check dimensionality . (3, torch.Size([174, 8, 8])) . means=torch.stack([x.mean(0) for x in train]) #Compute the average digit for i in range(10): show_image(means[i]) . F.l1_loss(test[0][0],means[0]),F.mse_loss(test[0][0],means[0]).sqrt() . (tensor(1.4324), tensor(2.2704)) . def mnist_distance(a,b): return (a-b).abs().mean((-1,-2)) mnist_distance(train,means) # Intentional error to demonstrate . RuntimeError Traceback (most recent call last) /tmp/ipykernel_48/3541699495.py in &lt;module&gt; 1 def mnist_distance(a,b): return (a-b).abs().mean((-1,-2)) -&gt; 2 mnist_distance(train,means) # Intentional error to demonstrate /tmp/ipykernel_48/3541699495.py in mnist_distance(a, b) -&gt; 1 def mnist_distance(a,b): return (a-b).abs().mean((-1,-2)) 2 mnist_distance(train,means) # Intentional error to demonstrate RuntimeError: The size of tensor a (154) must match the size of tensor b (10) at non-singleton dimension 1 . means.shape, train.shape,means.unsqueeze(1).shape #Failure to broadcast generates above error because broadcasting requires equal dimension #with different size. Unsqueeze to add dimension . (torch.Size([10, 8, 8]), torch.Size([10, 154, 8, 8]), torch.Size([10, 1, 8, 8])) . res=mnist_distance(train,means.unsqueeze(1)) print(res,res.shape) #The result is 10 vectors each with 154 elements. Per the shapes spit out by previous cell #you can see that the Means is being broadcast across the singleton dimension. What this means #is that vector n in the 1st dimension of the result contains the result of the mean value for digit n compared #against all 154 samples of train data for digit n. #This allows us to see the best and worst samples of each digit #View &#39;best&#39; and &#39;worst&#39; digits bestWorstIndex=[(list(x).index(min(x)),list(x).index(max(x))) for x in res] i=0 for b,w in bestWorstIndex: show_image(train[i][b]) show_image(train[i][w]) i=i+1 . tensor([[1.0852, 1.7360, 1.5692, ..., 1.4915, 1.1106, 1.2622], [1.7138, 2.3743, 2.4055, ..., 2.9948, 3.0561, 3.4396], [3.0636, 2.3867, 1.5756, ..., 1.7931, 2.0594, 1.7491], ..., [2.2926, 2.0388, 2.7857, ..., 2.2317, 2.0384, 2.2423], [2.1914, 2.4976, 2.1855, ..., 2.0434, 2.7443, 3.2455], [2.4969, 2.7304, 2.5003, ..., 1.8816, 2.7387, 2.2446]]) torch.Size([10, 154]) . #% accuracy for our baseline model. In that case we want each digit in test set compared #against every mean digit, and then to observe, for each test digit, comparison against #which mean yielded least difference? To do that we need to broadcast more print(&#39;shape of means :&#39;+ str(means.unsqueeze(1).unsqueeze(1).shape)) print(&#39;shape of train data :&#39;+ str(train.unsqueeze(0).shape)) #First of all, we want to unsqueeze the training tensor so that we can broadcast it up, creating multiple copies of itself #in that higher dimension. We want to have one copy of the training data for each of the mean (&#39;ideal&#39;) digits #for comparison, thats why we do that. Creating singleton dimensions allows for broadcasting to essentially create copies of #the data contained in the lower dimensions of the container. # #The means s unsqueezed multiple times because we want copies of copies of each of the mean digits. We unsqueeze at the first #index so that the dimension where the differentiation between digits occurs stays at the highest dimension # #The result is that the 10,1,1,8,8 tensor and 1,10,154,8,8 tensors are broadcast to be equal in shape to perform #computation. First in dimension 1, the train data is broadcast (10 copies created), in dimension 2 the mean data is broadcast #creating 10 copies of everything below. Then in the 3rd dimension, the means is again broadcast up to 154, creating 154 more #copies of what is in the dimensions below. In this way, the 1st dimension corresponds to the different &#39;ideal&#39; or mean #digits 0-9, the 2nd dimension corresponds to all the data corresponding to the training data for digits 0-9. The 3rd #dimension differentiates between individual samples of a given training digit. And the 4th and 5th dimension get us to #individual pixels # all_comparison=mnist_distance(means.unsqueeze(1).unsqueeze(1),train.unsqueeze(0)) print(&#39;shape of all comparison: &#39;+str(all_comparison.shape)) #The result is 3 instead of 5 dimensions because the mnist function took the average across the last two dimensions #reducing the data in them to a scalar stored in the 3rd dimension. So for axis i in the first dimension, we have #10 collections of data, which is the ideal digit i compared against the 154 samples for each digit as indexed in #the 2nd dimension #Picturing the 3D result as a cube, each element in the cube contains the numeric result from mnist_dist for the comparison #of ideal and test image. For a given test digit, it is compared against all 9 ideal digits, and the miniumum mnist_distance #should correspond to the digit that the training digit actually is. Therefore we iterate through taking slices of the cube #where in each iteration, a slice corresponds to all 154 training images for one and the same digit, each compared against #all 9 ideal digits def acc_rslt(comp): c=comp.clone() x,y,z=[i for i in c.shape] totSamp=y*z totCorrect=0 #Tallier confM=[] #confusion matrix will be result of stacking the bincount results for i in range(10): #Taking slice yields 2D object, shape (10,154), take min in each column (axis 1) to get digit prediction id=c[:,i,:].min(dim=0).indices # Retrieve indices i.e. predictions for all comparisons predCnt=torch.bincount(id,minlength=10) #Yields a 1D tensor with count of integers indexed by integer totCorrect=totCorrect+predCnt[i] confM.append(predCnt) confM=torch.stack(confM) return (totCorrect/totSamp*100),confM acc,conf=acc_rslt(all_comparison) print(&#39;accuracy: &#39;+str(round(acc.item(),2))+&#39;%&#39;) df = pd.DataFrame(conf) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) df.style.set_caption(&quot;Top Axis: Predicted value. Left Axis: Actual Value&quot;) . shape of means :torch.Size([10, 1, 1, 8, 8]) shape of train data :torch.Size([1, 10, 154, 8, 8]) shape of all comparison: torch.Size([10, 10, 154]) accuracy: 89.94% . Top Axis: Predicted value. Left Axis: Actual Value &nbsp; 0 1 2 3 4 5 6 7 8 9 . 0 153 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 124 | 8 | 1 | 0 | 2 | 4 | 0 | 4 | 11 | . 2 0 | 6 | 136 | 4 | 0 | 0 | 0 | 2 | 5 | 1 | . 3 1 | 0 | 1 | 143 | 0 | 0 | 0 | 4 | 2 | 3 | . 4 1 | 3 | 0 | 0 | 143 | 0 | 0 | 7 | 0 | 0 | . 5 1 | 0 | 0 | 1 | 1 | 131 | 3 | 0 | 0 | 17 | . 6 1 | 1 | 0 | 0 | 1 | 0 | 151 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 1 | 1 | 0 | 152 | 0 | 0 | . 8 0 | 15 | 2 | 2 | 0 | 4 | 2 | 2 | 119 | 8 | . 9 0 | 3 | 0 | 5 | 4 | 1 | 0 | 6 | 2 | 133 | . train_x = torch.cat([x for x in train]).view(-1, 8*8) test_x = torch.cat([x for x in test]).view(-1, 8*8) train_y, test_y =[],[] for n in range(10): train_y.extend([n]*154) test_y.extend([n]*20) train_y=tensor(train_y).unsqueeze(-1) test_y=tensor(test_y).unsqueeze(-1) train_x.shape,test_x.shape,train_y.shape,test_y.shape . (torch.Size([1540, 64]), torch.Size([200, 64]), torch.Size([1540, 1]), torch.Size([200, 1])) . dset=list(zip(train_x,train_y)) #Zip each input data item to its target output valid_dset=list(zip(test_x,test_y)) #Define DataLoader objects to pass to learner dl=DataLoader(dset,batch_size=25,shuffle=true) valid_dl=DataLoader(valid_dset,batch_size=5,shuffle=true) dls=DataLoaders(dl,valid_dl) . Implementing Net, Learning using custom defined model, learner.. . def init_params(size,std=.1): return (torch.randn(size)*std).requires_grad_() . torch.randn?? . w1=init_params((8*8,1)) #Have to provide extra dimension for matrix mutiplication, making it a single-column vector b1=init_params(1) w2=init_params((1,10)) # Have to provide an extra dimension (1) for matrix multiplication b2=init_params(1) #w1,b1,w2,b2 . def myModel(xb): res= xb@w1+b1 res=res.max(tensor(0.)) res=res@w2+b2#returns 10 features for each input return res . def myModel(xb): res= xb@w1+b1 #res=res.max(tensor(0.)) res=res@w2+b2#returns 10 features for each input return res . mini_samp=5 mini_x=train_x[:mini_samp] #Define a minibatch to test that the model works as intended w.r.t broadcasting across different tensor sizes... mini_y=train_y[:mini_samp] . myModel(mini_x) #test model.. output is a tensor of 10 elements per input image.. #each to be interpreted as activation for a given digit as being predicted . tensor([[ 3.3562, -3.1369, -3.0656, -2.9660, 3.1947, 2.4069, 3.5504, -3.1804, -2.6910, -2.5367], [ 4.2326, -4.0526, -3.9617, -3.8346, 4.0265, 3.0212, 4.4803, -4.1081, -3.4837, -3.2867], [ 3.1284, -2.8989, -2.8327, -2.7402, 2.9784, 2.2472, 3.3086, -2.9392, -2.4849, -2.3417], [ 5.2939, -5.1616, -5.0468, -4.8864, 5.0338, 3.7653, 5.6065, -5.2316, -4.4436, -4.1951], [ 4.4871, -4.3187, -4.2219, -4.0869, 4.2681, 3.1997, 4.7504, -4.3776, -3.7139, -3.5046]], grad_fn=&lt;AddBackward0&gt;) . def my_loss(preds,target,lr=0.01): #softmax returns a larger value for a given index, the larger that number was in proportion to the others #it motivates the network to reduce confidence in other choices at same time as increasing confidence in single output #Take the inverse since the goal is to reduce loss #Understanding that the largest activation is the prediction. # Recall the input is variable [minibatch] size. maxes=F.softmax(preds,dim=-1) correctIndices=[r[t] for r,t in zip(maxes,target)] resy=[-torch.log(tens) for tens in correctIndices] return sum(resy) #The above lines were tested to ensure the operations (softmax, indexing, -log, sum) retain gradient . maxes=F.softmax(myModel(mini_x),dim=-1) torch.log(maxes) #Observe! The softmax loss function yields -inf sometimes which will not allow for computaiton of meaningful gradient.. #If it didn&#39;t this time, just try different input (re run parameter initialization) . tensor([[ -9.9796, -0.6258, -1.2575, -6.4255, -4.6406, -3.7542, -10.6129, -8.0086, -4.6604, -1.9932], [ -6.6498, -0.9041, -1.2921, -4.4667, -3.3703, -2.8258, -7.0388, -5.4391, -3.3824, -1.7440], [ -8.9221, -0.6952, -1.2507, -5.7962, -4.2263, -3.4467, -9.4791, -7.1886, -4.2437, -1.8978], [ -1.0974, -9.4461, -8.8823, -4.2696, -5.8627, -6.6539, -0.5322, -2.8566, -5.8451, -8.2257], [ -4.8328, -1.1909, -1.4368, -3.4490, -2.7541, -2.4089, -5.0793, -4.0654, -2.7617, -1.7233]], grad_fn=&lt;LogBackward0&gt;) . #to numeric underflow, resulting in trying to take the log of 0, and having undefined (-inf) results #that cannot be differentiated.. maxes=F.softmax(myModel(mini_x),dim=-1) correctIndices=tensor([r[t] for r,t in zip(maxes,mini_y)]) myModel(mini_x),mini_y,maxes,correctIndices,torch.log(correctIndices) . (tensor([[-4.1185, 5.2352, 4.6036, -0.5644, 1.2204, 2.1069, -4.7518, -2.1475, 1.2007, 3.8679], [-2.4601, 3.2856, 2.8976, -0.2769, 0.8195, 1.3640, -2.8491, -1.2493, 0.8073, 2.4457], [-3.6006, 4.6264, 4.0708, -0.4746, 1.0952, 1.8748, -4.1576, -1.8670, 1.0779, 3.4238], [ 4.0184, -4.3303, -3.7665, 0.8462, -0.7469, -1.5381, 4.5836, 2.2592, -0.7293, -3.1099], [-1.4931, 2.1488, 1.9029, -0.1093, 0.5857, 0.9308, -1.7396, -0.7257, 0.5780, 1.6164]], grad_fn=&lt;AddBackward0&gt;), tensor([[0], [0], [0], [0], [0]]), tensor([[4.6336e-05, 5.3481e-01, 2.8437e-01, 1.6197e-03, 9.6515e-03, 2.3419e-02, 2.4597e-05, 3.3259e-04, 9.4631e-03, 1.3626e-01], [1.2943e-03, 4.0489e-01, 2.7469e-01, 1.1486e-02, 3.4380e-02, 5.9262e-02, 8.7718e-04, 4.3435e-03, 3.3966e-02, 1.7481e-01], [1.3341e-04, 4.9899e-01, 2.8630e-01, 3.0391e-03, 1.4606e-02, 3.1851e-02, 7.6432e-05, 7.5518e-04, 1.4355e-02, 1.4990e-01], [3.3373e-01, 7.8998e-05, 1.3882e-04, 1.3987e-02, 2.8436e-03, 1.2890e-03, 5.8731e-01, 5.7462e-02, 2.8941e-03, 2.6769e-04], [7.9645e-03, 3.0395e-01, 2.3768e-01, 3.1778e-02, 6.3669e-02, 8.9912e-02, 6.2240e-03, 1.7157e-02, 6.3182e-02, 1.7848e-01]], grad_fn=&lt;SoftmaxBackward0&gt;), tensor([4.6336e-05, 1.2943e-03, 1.3341e-04, 3.3373e-01, 7.9645e-03]), tensor([-9.9796, -6.6498, -8.9221, -1.0974, -4.8328])) . lossResults=my_loss(myModel(mini_x),mini_y) #Testing the loss function works(assuming mini_x of 3 samples) lossResults . tensor([31.4817], grad_fn=&lt;AddBackward0&gt;) . #to avoid underflow. Trying out basic code from the doc&#39;s here: loss = nn.CrossEntropyLoss() input = torch.randn(3, 5, requires_grad=True) target = torch.empty(3, dtype=torch.long).random_(5) output = loss(input, target) input,target . (tensor([[ 1.9199, -0.2254, -0.3417, 0.3040, -0.6890], [-1.1267, -0.2858, -1.0935, 1.1351, 0.7592], [-3.5945, 0.0192, 0.1052, 0.9603, -0.5672]], requires_grad=True), tensor([4, 1, 2])) . lossy=nn.CrossEntropyLoss() inp=myModel(mini_x) otpt=torch.cat(list(mini_y)) lossy(inp,otpt) . tensor(6.2963, grad_fn=&lt;NllLossBackward0&gt;) . . #The ideal loss function returns less loss if either confidence of right digit increases, or confidence #of wrong digit decreases. From this rational I get this: #Loss=sum(abs([model outputs for wrong digits]))/([Model output for right digit]) #This way, loss goes down as input for right digit goes up, and loss goes up as input for wrong digits go up def my_loss(preds,target): #Picked up a trick to place 0s at specfic indices in a tensor here:https://discuss.pytorch.org/t/creating-big-tensors-and-insert-ones-at-specific-dimensions/100025/2 #But it only works for 3D tensors and I couldnt find out how to generalize it to 2... so the following lines do some unsqueezing #To singleton upscale existing tensors to make this work. essentially getting a 0s/1s tensor with 1 at target indicies #to facilitate the loss calculation by isolating target values zeros=torch.zeros(preds.shape).unsqueeze(0) tgts=target.squeeze(1).unsqueeze(0) zeros[range(tgts.shape[0]), torch.tensor([range(tgts.shape[1])] * tgts.shape[0]).T, tgts.T] = 1 #Make target indices=1 targets_as_ones=zeros[0] #This retrieves the 2D tensor from the singleton 3D tensor targets_as_zeros=torch.where(targets_as_ones==0,1.,0.) targets=preds.unsqueeze(0)[range(tgts.shape[0]), torch.tensor([range(tgts.shape[1])] * tgts.shape[0]).T, tgts.T] #Pull out the NN output for the neuron #that represents the target value for that item. return abs(preds*targets_as_zeros/targets).sum() . my_loss(myModel(mini_x),mini_y) . tensor(31.4133, grad_fn=&lt;SumBackward0&gt;) . preds=myModel(mini_x) zeros=torch.zeros(preds.shape).unsqueeze(0) tgts=mini_y.squeeze(1).unsqueeze(0) zeros[range(tgts.shape[0]), torch.tensor([range(tgts.shape[1])] * tgts.shape[0]).T, tgts.T] = 1 #Make target indices=1 targets_as_ones=zeros[0] #This retrieves the 2D tensor from the singleton 3D tensor targets_as_zeros=torch.where(targets_as_ones==0,1.,0.) targets=preds.unsqueeze(0)[range(tgts.shape[0]), torch.tensor([range(tgts.shape[1])] * tgts.shape[0]).T, tgts.T] preds*targets_as_zeros,preds*targets_as_ones,preds.unsqueeze(0)[range(tgts.shape[0]), torch.tensor([range(tgts.shape[1])] * tgts.shape[0]).T, tgts.T] . (tensor([[-0.0000, 5.2352, 4.6036, -0.5644, 1.2204, 2.1069, -4.7518, -2.1475, 1.2007, 3.8679], [-0.0000, 3.2856, 2.8976, -0.2769, 0.8195, 1.3640, -2.8491, -1.2493, 0.8073, 2.4457], [-0.0000, 4.6264, 4.0708, -0.4746, 1.0952, 1.8748, -4.1576, -1.8670, 1.0779, 3.4238], [ 0.0000, -4.3303, -3.7665, 0.8462, -0.7469, -1.5381, 4.5836, 2.2592, -0.7293, -3.1099], [-0.0000, 2.1488, 1.9029, -0.1093, 0.5857, 0.9308, -1.7396, -0.7257, 0.5780, 1.6164]], grad_fn=&lt;MulBackward0&gt;), tensor([[-4.1185, 0.0000, 0.0000, -0.0000, 0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000], [-2.4601, 0.0000, 0.0000, -0.0000, 0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000], [-3.6006, 0.0000, 0.0000, -0.0000, 0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000], [ 4.0184, -0.0000, -0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000, -0.0000, -0.0000], [-1.4931, 0.0000, 0.0000, -0.0000, 0.0000, 0.0000, -0.0000, -0.0000, 0.0000, 0.0000]], grad_fn=&lt;MulBackward0&gt;), tensor([[-4.1185], [-2.4601], [-3.6006], [ 4.0184], [-1.4931]], grad_fn=&lt;IndexBackward0&gt;)) . abs(preds*targets_as_zeros/targets).sum() . tensor(31.4133, grad_fn=&lt;SumBackward0&gt;) . #Trying again but even simpler.. just maximize activation of target neuron def my_loss(preds,target): tgts=target.squeeze(1).unsqueeze(0) targets=preds.unsqueeze(0)[range(tgts.shape[0]), torch.tensor([range(tgts.shape[1])] * tgts.shape[0]).T, tgts.T] #Pull out the NN output for the neuron return abs(1/targets).sum() #Invert them because we want to minimize loss. So the larger the absolute activation, smaller loss . #Need to incorporate cost of being wrong. This one tries to do so by returning the average ratio of #wrong activation vs right activation. Notice that activation are not abs() in taking ratio.. #I think that allowing activation of wrong value to continue to be forced down into negative dimension gives more #freedom for learning... Because there is more room on interval of [-inf,+inf] than [0,+inf], so more #room for differentiating prediction to capitalize on def my_loss(preds,target): tgts=target.squeeze(1).unsqueeze(0) targets=preds.unsqueeze(0)[range(tgts.shape[0]), torch.tensor([range(tgts.shape[1])] * tgts.shape[0]).T, tgts.T] #Pull out the NN output for the neuron return (preds/targets).mean() . #and found perhaps I shouldve used the cross entropy function as my loss function... #=-log(softmax value of correct activation unit) . def my_loss(preds,target): loss_fn=nn.CrossEntropyLoss() tgts=target.view(-1)#Turn tensor of singleton tensors one per target into a single tensor with all as elements return loss_fn(preds,tgts) #Nice . def batch_accuracy(mdl,xb, yb): otpts = mdl(xb) #Get output activations from model preds= otpts.max(dim=-1).indices #The indices of the max activation is the predicted digit of the input correct=preds==yb.view(-1) #Types must be tensors to return sequence of true/false # Use view to take it from shape=[5,1] to [5], same as preds. else will broadcast and end result all messed up return correct.float().mean() def validate_epoch(mdl): outcomes=[batch_accuracy(mdl,xb,yb) for xb,yb in valid_dl] return round(torch.stack(outcomes).mean().item(),4) . #This is to valdiate that we&#39;re pulling the right data, so as to validate the validate_epoch function validIter=iter(dls[1]) xv,yv=next(validIter) for i in range(len(xv)): show_image(xv[i].view((8,8))) print(yv[i].data.item()) . 9 0 6 6 9 . #batch_accuracy otuput to validate its correct validIter=iter(dls[1]) xv,yv=next(validIter) o=myModel(xv) print(o.max(dim=-1).indices,yv,batch_accuracy(myModel,xv,yv)) . tensor([1, 1, 6, 1, 1]) tensor([[3], [7], [0], [1], [4]]) tensor(0.1600) . o . tensor([[-6.1172, 7.5849, 6.6596, -0.9109, 1.7037, 3.0022, -7.0449, -3.2300, 1.6748, 5.5819], [-8.4815, 10.3643, 9.0917, -1.3208, 2.2753, 4.0613, -9.7575, -4.5104, 2.2356, 7.6094], [ 0.4390, -0.1225, -0.0845, 0.2257, 0.1185, 0.0653, 0.4770, 0.3207, 0.1197, -0.0404], [-5.2695, 6.5883, 5.7876, -0.7640, 1.4987, 2.6225, -6.0723, -2.7709, 1.4737, 4.8550], [-4.3495, 5.5068, 4.8412, -0.6045, 1.2763, 2.2103, -5.0168, -2.2726, 1.2555, 4.0660]], grad_fn=&lt;AddBackward0&gt;) . myModel(mini_x),mini_y,batch_accuracy(myModel,mini_x,mini_y),validate_epoch(myModel) #validate the function works right... #since train_y and _x were organized with digits in sequence (0&#39;s, then 1&#39;s, etc...), the first 5 digits #being tested here are all 0&#39;s. Observe that if 1/5 outputs max value is in 0 index, then the accuracy is 0.2 #Might take initializing new parameters multiple times to get a correct guess, it will be random #Given the relu activation, the model may yield multiple identical values for multiple guesses/vectors when relu activation #was zero. In this case, the max function returns the 0 index, and 0 is the target, so 0&#39;s will be right. #tbh i think this is a weakness with this model, and having a different randomly initialized bias for each feature would #eliminate this and be better . (tensor([[-4.1185, 5.2352, 4.6036, -0.5644, 1.2204, 2.1069, -4.7518, -2.1475, 1.2007, 3.8679], [-2.4601, 3.2856, 2.8976, -0.2769, 0.8195, 1.3640, -2.8491, -1.2493, 0.8073, 2.4457], [-3.6006, 4.6264, 4.0708, -0.4746, 1.0952, 1.8748, -4.1576, -1.8670, 1.0779, 3.4238], [ 4.0184, -4.3303, -3.7665, 0.8462, -0.7469, -1.5381, 4.5836, 2.2592, -0.7293, -3.1099], [-1.4931, 2.1488, 1.9029, -0.1093, 0.5857, 0.9308, -1.7396, -0.7257, 0.5780, 1.6164]], grad_fn=&lt;AddBackward0&gt;), tensor([[0], [0], [0], [0], [0]]), tensor(0.), 0.115) . testLoader=iter(dls[0]) . lr=0.01 xb,yb=next(testLoader) loss=my_loss(myModel(xb),yb) loss.backward() with torch.no_grad(): for p in w1,b1,w2,b2: p.data= p.data-p.grad.data*lr p.grad.zero_() print(loss) . tensor(8.6665, grad_fn=&lt;NllLossBackward0&gt;) . if type(w1.grad)==NoneType: print(tensor([(x.data.mean()) for x in [w1,b1,w2,b2]])) else: print(tensor([(x.data.mean(),x.grad.data.mean()) for x in [w1,b1,w2,b2]])) for p in w1,b1,w2,b2: p.grad.zero_() . tensor([[ 0.0036, 0.0000], [ 0.0641, 0.0000], [-0.0487, 0.0000], [ 0.1809, 0.0000]]) . #Running this one and then cell below will allow to observe changes in the parameters #as a result of back propagation and gradient descent! #If change to parameters is not observed, run cell below to verify non zero gradient is being computed lr=0.01 for xb,yb in dls[0]: loss=my_loss(myModel(xb),yb) loss.backward() with torch.no_grad(): for p in w1,b1,w2,b2: p.data= p.data-p.grad.data*lr p.grad.zero_() print(loss) #Prints loss for each minibatch . tensor(7.8955, grad_fn=&lt;NllLossBackward0&gt;) tensor(5.5976, grad_fn=&lt;NllLossBackward0&gt;) tensor(6.0172, grad_fn=&lt;NllLossBackward0&gt;) tensor(5.6406, grad_fn=&lt;NllLossBackward0&gt;) tensor(5.9263, grad_fn=&lt;NllLossBackward0&gt;) tensor(5.2161, grad_fn=&lt;NllLossBackward0&gt;) tensor(4.9269, grad_fn=&lt;NllLossBackward0&gt;) tensor(4.4739, grad_fn=&lt;NllLossBackward0&gt;) tensor(4.7216, grad_fn=&lt;NllLossBackward0&gt;) tensor(3.8051, grad_fn=&lt;NllLossBackward0&gt;) tensor(3.8510, grad_fn=&lt;NllLossBackward0&gt;) tensor(3.0392, grad_fn=&lt;NllLossBackward0&gt;) tensor(3.1438, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.8495, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.6098, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.7949, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.6347, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.4974, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.3163, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2406, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1818, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.3660, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2306, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2963, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0940, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2297, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2294, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1313, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2549, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1769, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1987, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2986, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2026, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1892, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.3056, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1602, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0594, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.3139, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2606, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0796, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0918, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1626, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1314, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1663, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1291, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2918, grad_fn=&lt;NllLossBackward0&gt;) tensor(1.9681, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0553, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2321, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0318, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0983, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.4087, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1333, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2700, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2204, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0809, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1463, grad_fn=&lt;NllLossBackward0&gt;) tensor(1.9678, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1310, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.0630, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.1422, grad_fn=&lt;NllLossBackward0&gt;) tensor(2.2210, grad_fn=&lt;NllLossBackward0&gt;) . #(Running this one and then the above will allow for verification/display of computation result of non zero gradients) def calc_grad(xb, yb, model,f_loss): preds = model(xb) loss = f_loss(preds, yb) loss.backward() return loss.data.item() #Return the loss (see why later) calc_grad(mini_x,mini_y,myModel,my_loss) . 2.0894858837127686 . #Running this then the print cell 2 above will allow for validation of code by observing parameter change. If no change, #Run one above to check gradient size def train_epoch(model,lr,params,f_loss): for xb,yb in dls[0]: calc_grad(xb,yb,model,f_loss) with torch.no_grad(): for p in w1,b1,w2,b2: p.data= p.data-p.grad.data*lr p.grad.zero_() train_epoch(myModel,0.01,[w1,b1,w2,b2],my_loss) . class BasicOptim: def __init__(self,params,lr): self.params,self.lr = list(params),lr def step(self, *args, **kwargs): for p in self.params: p.data -= p.grad.data * self.lr def zero_grad(self, *args, **kwargs): for p in self.params: p.grad = None . def train_epoch(model,opt,lr,params,f_loss): losses=[]#Will allow for recording epoch wise loss for xb,yb in dls[0]: calc_grad(xb,yb,model,f_loss) opt.step() losses.append(calc_grad(xb,yb,model,f_loss)) opt.zero_grad() return tensor(losses) #Will allow for analyzing performance w.r.t loss as the model learns . my_opt=BasicOptim([w1,b1,w2,b2],0.01) res=train_epoch(myModel,my_opt,0.01,[w1,b1,w2,b2],my_loss) res.mean(),res . (tensor(2.0317), tensor([2.0741, 1.7660, 2.2313, 1.9984, 1.8884, 2.1686, 1.7515, 2.0124, 1.9008, 2.1306, 2.1752, 1.9439, 1.9268, 1.9860, 2.1010, 2.1853, 2.2638, 2.2290, 1.9893, 1.9734, 1.9442, 2.0295, 2.1597, 2.0376, 2.0211, 2.0450, 1.9879, 2.1127, 1.8709, 1.9576, 2.1561, 1.9560, 2.1379, 2.0640, 2.0666, 1.9608, 2.0936, 2.2478, 2.1695, 2.0455, 1.8293, 2.0236, 2.0528, 2.0663, 2.1181, 1.8855, 2.1618, 2.0844, 1.7411, 1.9947, 1.8307, 1.8846, 1.9199, 1.9247, 1.9935, 2.1115, 2.2204, 2.1065, 2.1304, 1.9570, 1.9483, 2.2220])) . class cTrial: def __init__(self,numE=10,lr=0.01,model=myModel,opt=my_opt,params=[w1,b1,w2,b2],f_loss=my_loss): self.numE=numE self.lr=lr self.model=model self.opt=opt self.params=params self.f_loss=f_loss self.res=[] self.valids=[] self.wtsHist=[] # For tracking change in weights across learning def run(self,numE=None,wkLr=None): self.valids=[] #Reset epch_losses=[] #Reset self.wtsHist=[[],[],[],[]] # 4 contents, w1,b1,w2,b2 if numE is None: numE=self.numE if wkLr is None: wkLr=self.lr for i in range(numE): #-- Record wts for analysis self.wtsHist[0].append(list(x.item() for x in w1.data.view(-1))) self.wtsHist[1].append(list(x.item() for x in b1.data.view(-1))) self.wtsHist[2].append(list(x.item() for x in w2.data.view(-1))) self.wtsHist[3].append(list(x.item() for x in b2.data.view(-1))) #-- res=train_epoch(self.model,self.opt,self.lr,self.params,self.f_loss) epch_losses.append(res) self.valids.append(validate_epoch(self.model)) self.res=torch.stack(epch_losses) self.valids=tensor(self.valids) #self.wtsHist=[tensor([self.wtsHist[0],self.wtsHist[2]]),tensor([self.wtsHist[1],self.wtsHist[3]])] #self.res=epch_losses . #Leaving off with the below cell failing and I can&#39;t really imagine why... #Also the basic &#39;activation maximizer&#39; is at risk of naively increasing ALL activations #Empirically after many epochs it just chooses 1 digit for everything even as loss goes down. #Need to somehow include cost of being wrong agian.. Maybe sum the average of wrong activation/tgt activation! . #Leaving off having found that commenting out the ReLu layer stops the behaviour where the gradient was zeroing out on w1,b1,w2 #Also implemented the &#39;average ratio of wrong activation against right one&#39; loss function #Still observing that the NN is resorting to naively estimating 1 digit, resulting in constant 10% sucess rate... #Was working on a function to plot the weight changes across epochs to monitor for wierd behaviour.. #basically cast the list output as a tensor.. iterate through *columns* with .view()to get parameter wise data across iterations . my_try=cTrial() my_try.run(numE=50,wkLr=0.001) my_try.res.shape #We see the result is a tensor of numE tensors of 62 results. We initiated the dataLoaders #with 25 items to a minibatch, with 1540 data samples across all inputs, 25*62=1550, so we have 61 minibatches of 25 with #one last minibatch of 15 . torch.Size([50, 62]) . my_try.res.mean(dim=1) #Return average loss across all minibatches in each epoch, in chronological sequence. #If loss is going down... SUCCESS!!! (or at least its working as intended!) . tensor([2.0169, 1.9830, 1.9666, 1.9293, 1.9145, 1.8770, 1.8447, 1.8138, 1.7978, 1.7788, 1.7664, 1.7587, 1.7477, 1.7338, 1.7375, 1.7188, 1.7214, 1.7153, 1.7065, 1.6975, 1.7047, 1.6953, 1.6931, 1.6909, 1.6839, 1.6845, 1.6900, 1.6598, 1.6593, 1.6518, 1.6599, 1.6535, 1.6382, 1.6410, 1.6291, 1.6362, 1.6249, 1.6178, 1.6197, 1.6216, 1.6137, 1.6149, 1.6176, 1.6130, 1.6013, 1.6048, 1.6106, 1.6056, 1.6002, 1.5979]) . plt.plot(my_try.res.mean(dim=1)) . [&lt;matplotlib.lines.Line2D at 0x7f19f8e3eb50&gt;] . plt.plot(my_try.valids) . [&lt;matplotlib.lines.Line2D at 0x7f19f9798dd0&gt;] . #What I&#39;m observing is the model always settles on choosing one of 2 possible digits, #(seemingly random based on initial condition), so its performance still sucks. #Wondering: What if it needs greater capacity? Greater layers? #-&gt; going to redefine model.. . W1=init_params((8*8,32)) #64 in, 32 out B1=init_params(32) # Feature-specific biases added W2=init_params((32,16)) # 32 in, 16 out B2=init_params(16) # Feature-specific biases added W3=init_params((16,10)) # 16 in, 10 out B3=init_params(10) # Feature-specific biases added . def mdlV2(xb): res= xb@W1+B1 res=res.max(tensor(0.)) res=res@W2+B2#returns 10 features for each input res=res.max(tensor(0.)) res=res@W3+B3#returns 10 features for each input return res . mdlV2(mini_x) #Test with random data sample to see the matrix multiplication works, parameters defined correctly... . tensor([[ 1.0679, -1.8199, 0.4861, -0.6773, -0.4341, -0.0244, -1.4107, 0.5197, 0.7869, 0.7355], [ 1.2566, -2.1620, 0.7953, -0.5469, -0.4030, -0.2573, -1.2032, 0.9089, 0.6863, 0.8816], [ 1.6671, -2.5187, 0.7505, -0.6515, -0.0254, 0.0655, -1.9130, 0.6849, 0.3266, 0.2800], [ 1.3645, -2.4120, 0.5461, -0.7007, -0.4227, -0.1179, -1.6952, 0.9528, 0.6045, 1.0226], [ 1.7769, -2.7423, 0.7523, -0.8904, -0.1210, 0.1373, -2.2262, 0.8818, 0.4147, 0.6171]], grad_fn=&lt;AddBackward0&gt;) . my_try=cTrial(model=mdlV2,opt=BasicOptim([W1,B1,W2,B2,W3,B3],0.01),params=[W1,B1,W2,B2,W3,B3]) my_try.run(numE=20,wkLr=20) . plt.plot(my_try.res.mean(dim=1)[1:]) . [&lt;matplotlib.lines.Line2D at 0x7f19f3563610&gt;] . plt.plot(my_try.valids) . [&lt;matplotlib.lines.Line2D at 0x7f19f34de510&gt;] . #to get a sense for the outputs . def viewSamplePredictions(model): validIter=iter(dls[1]) xv,yv=next(validIter) o=model(xv) print(o.max(dim=-1).indices,yv,batch_accuracy(model,xv,yv)) viewSamplePredictions(mdlV2) . tensor([4, 4, 4, 4, 4]) tensor([[2], [7], [0], [2], [1]]) tensor(0.) . def confMtx(model): conf=torch.zeros([10, 10],dtype=torch.int32) for xv,yv in dls[1]: preds=model(xv).max(dim=-1).indices for i in range(len(xv)): conf[yv[i].item()][preds[i].item()]+=1 df = pd.DataFrame(conf) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) return df.style.set_caption(&quot;Top Axis: Predicted value. Left Axis: Actual Value&quot;) #return df confMtx(mdlV2) . Top Axis: Predicted value. Left Axis: Actual Value &nbsp; 0 1 2 3 4 5 6 7 8 9 . 0 18 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | . 1 1 | 0 | 0 | 0 | 0 | 11 | 0 | 6 | 0 | 2 | . 2 0 | 0 | 0 | 11 | 0 | 0 | 0 | 0 | 0 | 9 | . 3 0 | 0 | 0 | 18 | 0 | 0 | 0 | 0 | 0 | 2 | . 4 4 | 0 | 0 | 0 | 0 | 0 | 13 | 2 | 0 | 1 | . 5 3 | 0 | 0 | 0 | 0 | 14 | 0 | 2 | 0 | 1 | . 6 9 | 0 | 0 | 0 | 0 | 1 | 10 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 7 | 0 | 2 | 0 | 2 | 0 | 9 | . 8 3 | 0 | 0 | 0 | 0 | 12 | 0 | 0 | 0 | 5 | . 9 0 | 0 | 0 | 5 | 0 | 4 | 0 | 1 | 0 | 10 | . #like mothers milk. But now its output space just lacks 0,3,7! Going to add greater capacity... #Funnel shaped NN . W1v3=init_params((8*8,48)) #64 in, 32 out B1v3=init_params(48) # Feature-specific biases added W2v3=init_params((48,32)) # 32 in, 16 out B2v3=init_params(32) # Feature-specific biases added W3v3=init_params((32,24)) # 16 in, 10 out B3v3=init_params(24) # Feature-specific biases added W4v3=init_params((24,18)) # 16 in, 10 out B4v3=init_params(18) W5v3=init_params((18,14)) B5v3=init_params(14) W6v3=init_params((14,10)) B6v3=init_params(10) . def mdlV3(xb): res= xb@W1v3+B1v3 res=res.max(tensor(0.)) res=res@W2v3+B2v3 res=res.max(tensor(0.)) res=res@W3v3+B3v3 res=res.max(tensor(0.)) res=res@W4v3+B4v3 res=res.max(tensor(0.)) res=res@W5v3+B5v3 res=res.max(tensor(0.)) res=res@W6v3+B6v3 return res . mdlV3(mini_x) . tensor([[ 345.8418, 289.0138, 60.7753, 223.0188, 113.1826, 104.4974, 336.0727, -771.3594, 334.1454, 381.0231], [ 210.8918, 151.5357, 136.3566, 221.9274, 72.0100, 221.6852, 366.7518, -573.8847, 342.6361, 68.7711], [ 509.5496, 318.0272, 156.9736, 234.6567, 102.3715, 238.3482, 468.9347, -909.8787, 501.5280, 275.4095], [ 318.9915, 458.8397, -21.3896, 186.9061, 23.5667, -189.7860, 74.7113, -610.5369, 152.0016, 583.3962], [ 353.9034, 382.0305, 125.8823, 263.3908, 93.5603, 96.6531, 309.1708, -652.4356, 318.3333, 234.5244]], grad_fn=&lt;AddBackward0&gt;) . my_try=cTrial(model=mdlV3,opt=BasicOptim([W1v3,B1v3,W2v3,B2v3,W3v3,B3v3,W4v3,B4v3,W5v3,B5v3,W6v3,B6v3],0.01),params=[W1v3,B1v3,W2v3,B2v3,W3v3,B3v3,W4v3,B4v3,W5v3,B5v3,W6v3,B6v3]) my_try.run(numE=100,wkLr=0.001) . plt.plot(my_try.res.mean(dim=1)[1:]) #Omit first result, makes end values not discriminable . [&lt;matplotlib.lines.Line2D at 0x7f19f9d83450&gt;] . plt.plot(my_try.valids) . [&lt;matplotlib.lines.Line2D at 0x7f19fa9df190&gt;] . viewSamplePredictions(mdlV3) . tensor([0, 0, 0, 0, 0]) tensor([[8], [0], [9], [2], [1]]) tensor(0.2000) . confMtx(mdlV3) . #Instead of funnel shape, Ill make it wormhole shape (trumpet bell.. start wide, go narrow fast but long) . W1v4=init_params((8*8,32)) #64 in, 32 out B1v4=init_params(32) # Feature-specific biases added W2v4=init_params((32,16)) # 32 in, 16 out B2v4=init_params(16) # Feature-specific biases added W3v4=init_params((16,10)) # 16 in, 10 out B3v4=init_params(10) # Feature-specific biases added W4v4=init_params((10,10)) # 16 in, 10 out B4v4=init_params(10) W5v4=init_params((10,10)) B5v4=init_params(10) W6v4=init_params((10,10)) B6v4=init_params(10) W7v4=init_params((10,10)) B7v4=init_params(10) W8v4=init_params((10,10)) B8v4=init_params(10) W9v4=init_params((10,10)) B9v4=init_params(10) W10v4=init_params((10,10)) B10v4=init_params(10) W11v4=init_params((10,10)) B11v4=init_params(10) W12v4=init_params((10,10)) B12v4=init_params(10) . def mdlV4(xb): res= xb@W1v4+B1v4 res=res.max(tensor(0.)) res=res@W2v4+B2v4 res=res.max(tensor(0.)) res=res@W3v4+B3v4 res=res.max(tensor(0.)) res=res@W4v4+B4v4 res=res.max(tensor(0.)) res=res@W5v4+B5v4 res=res.max(tensor(0.)) res=res@W6v4+B6v4 res=res.max(tensor(0.)) res=res@W7v4+B7v4 res=res.max(tensor(0.)) res=res@W8v4+B8v4 res=res.max(tensor(0.)) res=res@W9v4+B9v4 res=res.max(tensor(0.)) res=res@W10v4+B10v4 res=res.max(tensor(0.)) res=res@W11v4+B11v4 res=res.max(tensor(0.)) res=res@W12v4+B12v4 return res . mdlV4(mini_x)#Checking math works . tensor([[ 7.4950e+01, 1.7422e+02, -2.3696e+01, -3.5641e+01, 4.9170e+01, 1.5804e+02, 1.5012e+01, -1.2010e+02, 1.6857e+01, -5.1689e+01], [ 2.5860e+01, 5.2283e+01, -1.9358e+01, -2.6612e+01, 2.3746e+01, 3.8518e+01, 1.3859e-01, -3.9123e+01, -2.9411e+00, -4.1714e+01], [ 2.5161e+01, 6.0673e+01, -1.2859e+01, -2.2634e+01, 1.7738e+01, 5.2163e+01, 1.5605e+00, -4.2871e+01, -6.3931e-02, -2.9956e+01], [ 9.5547e+01, 2.3226e+02, -3.0140e+01, -5.3980e+01, 5.9029e+01, 2.2473e+02, 1.4448e+01, -1.5792e+02, 1.8842e+01, -7.1073e+01], [ 8.1295e+01, 1.9916e+02, -2.5350e+01, -4.7145e+01, 4.9380e+01, 1.9437e+02, 1.1905e+01, -1.3606e+02, 1.6377e+01, -6.0936e+01]], grad_fn=&lt;AddBackward0&gt;) . my_try=cTrial(model=mdlV4,opt=BasicOptim([W1v4,B1v4,W2v4,B2v4,W3v4,B3v4,W4v4,B4v4,W5v4,B5v4,W6v4,B6v4,W7v4,B7v4,W8v4,B8v4,W9v4,B9v4,W10v4,B10v4,W11v4,B11v4,W12v4,B12v4],0.01),params=[W1v4,B1v4,W2v4,B2v4,W3v4,B3v4,W4v4,B4v4,W5v4,B5v4,W6v4,B6v4,W7v4,B7v4,W8v4,B8v4,W9v4,B9v4,W10v4,B10v4,W11v4,B11v4,W12v4,B12v4]) my_try.run(numE=20,wkLr=10) . #With the multiple layers of multiplication... reducing variance of initial param random sampling mitigates this.. plt.plot(my_try.res.mean(dim=1)[1:]) #Omit first result, makes end values not discriminable . [&lt;matplotlib.lines.Line2D at 0x7f19f346e210&gt;] . plt.plot(my_try.valids) . [&lt;matplotlib.lines.Line2D at 0x7f19f33e3990&gt;] . viewSamplePredictions(mdlV4) . tensor([0, 0, 0, 0, 0]) tensor([[9], [5], [5], [6], [0]]) tensor(0.2000) . confMtx(mdlV4) . Top Axis: Predicted value. Left Axis: Actual Value &nbsp; 0 1 2 3 4 5 6 7 8 9 . 0 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 6 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 7 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 8 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 9 20 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . #Finding that training across just a few epochs, the model is learning to take a stab at all numbers! . #bad random starting place, then reduce over time to hone in on a local optimum... Can try this?... #Defining new function (alternatively could be made a method of Learner): def shrinkSteps(lrnr,numE,lrHi,lrLo): for lr in np.linspace(lrHi,lrLo,numE): lrnr.run(numE=1,wkLr=lr) . my_try=cTrial(model=mdlV4,opt=BasicOptim([W1v4,B1v4,W2v4,B2v4,W3v4,B3v4,W4v4,B4v4,W5v4,B5v4,W6v4,B6v4,W7v4,B7v4,W8v4,B8v4,W9v4,B9v4,W10v4,B10v4,W11v4,B11v4,W12v4,B12v4],0.01),params=[W1v4,B1v4,W2v4,B2v4,W3v4,B3v4,W4v4,B4v4,W5v4,B5v4,W6v4,B6v4,W7v4,B7v4,W8v4,B8v4,W9v4,B9v4,W10v4,B10v4,W11v4,B11v4,W12v4,B12v4]) shrinkSteps(my_try,8,.5,.01) #Unfortunately still naive at a broad range of values . #Now trying a needle format NN . W1v4=init_params((8*8,10)) #64 in, 10 out B1v4=init_params(1) W2v4=init_params((10,10)) B2v4=init_params(1) W3v4=init_params((10,10)) B3v4=init_params(1) W4v4=init_params((10,10)) B4v4=init_params(1) W5v4=init_params((10,10)) B5v4=init_params(1) W6v4=init_params((10,10)) B6v4=init_params(1) W7v4=init_params((10,10)) B7v4=init_params(1) W8v4=init_params((10,10)) B8v4=init_params(1) W9v4=init_params((10,10)) B9v4=init_params(1) W10v4=init_params((10,10)) B10v4=init_params(1) W11v4=init_params((10,10)) B11v4=init_params(1) W12v4=init_params((10,10)) B12v4=init_params(1) . #(Also fixed an error in how batch accuracy was computed...) #It turns out the size of parameters when initialized also has a huge impact on outcomes #Depending on shape of NN, large params can lead to naive selection of only a single digit that then never learns #I had reduced standard dev of initialization distribution when experimenting with later models, but this proved #just the trick for mdlV2! Achieved 93% digit recognition on the validation set! :) .",
            "url": "https://davidd003.github.io/Posts/fastai/jupyter/2022/08/02/Building-A-Digit-Classifier.html",
            "relUrl": "/fastai/jupyter/2022/08/02/Building-A-Digit-Classifier.html",
            "date": " • Aug 2, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://davidd003.github.io/Posts/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://davidd003.github.io/Posts/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am a Torontonian in London (Ontario): an avid (rabid) consumer of podcasts, interested in music and AI. . Fun fact! This website is powered by fastpages 1. I would encourage you tot ry it out. It’s free to host, easy to update, flexible, and fun to learn! . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://davidd003.github.io/Posts/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://davidd003.github.io/Posts/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}